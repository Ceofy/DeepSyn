{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224602975035165\t0.9999992682327138\t52381\n",
      "\n",
      "0.9224602975035165\t0.9999992682327138\t52381\n",
      "\n",
      "0.9224602975035165\t0.9999992682327138\t52381\n",
      "\n",
      "0\tsynthesis\t0.6512401536662175\n",
      "\n",
      "1\tprocesses\t0.6470964561054141\n",
      "\n",
      "2\ttelomere\t0.5895107717098585\n",
      "\n",
      "3\trecombination\t0.49487830896916124\n",
      "\n",
      "4\tlymphocytes\t0.49033595399822616\n",
      "\n",
      "5\tdeficient\t0.4855946278833006\n",
      "\n",
      "6\tcapacity\t0.46643945076622917\n",
      "\n",
      "7\tsyndrome\t0.46122116701714516\n",
      "\n",
      "8\tstudies\t0.44600149312887244\n",
      "\n",
      "9\tdna\t0.44440005241177716\n",
      "\n",
      "10\tbrca1\t0.44163888247118516\n",
      "\n",
      "11\tendonuclease\t0.4410565982959221\n",
      "\n",
      "12\tmechanisms\t0.4392912520779548\n",
      "\n",
      "13\tpolyadp-ribose\t0.43541277548363494\n",
      "\n",
      "14\tdamage\t0.42697981066586876\n",
      "\n",
      "15\tdose\t0.4233037684591899\n",
      "\n",
      "16\tirradiation\t0.4163641945798971\n",
      "\n",
      "17\tpatients\t0.412279437887678\n",
      "\n",
      "18\tover\t0.41198016316638203\n",
      "\n",
      "19\tcancer\t0.40897399924397004\n",
      "\n",
      "0\tprocesses\t0.6918614879595738\n",
      "\n",
      "1\tendonuclease\t0.6807678002835317\n",
      "\n",
      "2\ttelomere\t0.6597825449583822\n",
      "\n",
      "3\tgenotoxic\t0.63998431233852\n",
      "\n",
      "4\tsynthesis\t0.604088608190694\n",
      "\n",
      "5\tsurvival\t0.6024379211306635\n",
      "\n",
      "6\tcyclin\t0.5818061269986681\n",
      "\n",
      "7\trecombination\t0.5568641024720951\n",
      "\n",
      "8\tsuggest\t0.5547806313042397\n",
      "\n",
      "9\tconserved\t0.5406657806246268\n",
      "\n",
      "10\tmechanisms\t0.5265096242135119\n",
      "\n",
      "11\tpolyadp-ribose\t0.5121798613778428\n",
      "\n",
      "12\tstudies\t0.508399044504733\n",
      "\n",
      "13\tparp\t0.5080944459797869\n",
      "\n",
      "14\tmitochondrial\t0.4897555839041122\n",
      "\n",
      "15\tdoses\t0.4836126308152638\n",
      "\n",
      "16\tpossible\t0.47184281611837636\n",
      "\n",
      "17\tdefect\t0.4709777708752704\n",
      "\n",
      "18\tcarcinogens\t0.4684120184547135\n",
      "\n",
      "19\tdose\t0.4588831950120211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "repo_dir = '/oak/stanford/groups/rbaltman/swang91/Sheng_repo/'\n",
    "nlp_tool_dir = '/srv/local/work/swang141/PatientSetAnnotation/Sheng/analysis/stanford_parser_java/stanford-parser-full-2017-06-09/'\n",
    "sys.path.append(repo_dir)\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "from pikachu.datasets.WordNet import WordNet\n",
    "from pikachu.datasets.ImprovedWordNet import ImprovedWordNet\n",
    "from pikachu.utils.nlp import parse_word_net\n",
    "from pikachu.utils.evaluate.evaluate import evaluate_vec\n",
    "from pikachu.models.generate_sentence.extractive_gen import ExtractGenSent\n",
    "#from pikachu.datasets.SubGraph import SubGraph\n",
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "#from pikachu.plot.ScatterPlot import ScatterPlot\n",
    "from scipy import stats\n",
    "    \n",
    "stop_word_file = 'data/NLP_Dictionary/stopwords.txt'\n",
    "#stop_word_list = parse_word_net.GenerateStopWordList(Net_obj.word_ct,Net_obj.edge_ct,stop_word_file,Net_obj.word_type)\n",
    "stop_word_list = parse_word_net.GetStopWordList(stop_word_file)\n",
    "\n",
    "stop_word_list_manually = parse_word_net.GetStopWordList('data/NLP_Dictionary/stopwords_manually.txt')\n",
    "stop_word_list = stop_word_list.union(stop_word_list_manually)\n",
    "\n",
    "import multiprocessing\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import operator\n",
    "import collections\n",
    "import time\n",
    "\n",
    "\n",
    "nchunk = 400\n",
    "mode = 3#0: extract abs, 1: train_model, 2:generate sent\n",
    "server = 'sherlock'#'grenache''sherlock'\n",
    "if server == 'timan107':\n",
    "    pubmed_dir = '/srv/local/work/swang141/PatientSetAnnotation/Sheng/data/pubmed/'\n",
    "    GO_data_dir = '/srv/local/work/swang141/Sheng_repo/data/Pubmed/'\n",
    "    GO_term_file = '/srv/local/work/swang141/Sheng_repo/data/NLP_Dictionary/go_term.txt'\n",
    "    repo_dir = '/srv/local/work/swang141/Sheng_repo/'\n",
    "elif server == 'grenache':\n",
    "    pubmed_dir = '/data/cellardata/users/majianzhu/wangsheng/Sheng_repo/pubmed/'\n",
    "    GO_data_dir = '/cellar/users/majianzhu/Data/wangsheng/Sheng_repo/data/Pubmed/'\n",
    "    GO_term_file = '/data/cellardata/users/majianzhu/wangsheng/Sheng_repo/Sheng_repo/data/NLP_Dictionary/go_term.txt'\n",
    "    repo_dir = '/data/cellardata/users/majianzhu/wangsheng/Sheng_repo/Sheng_repo/'\n",
    "else:\n",
    "    pubmed_dir = '/oak/stanford/groups/rbaltman/swang91/Sheng_repo/data/Pubmed/pubmed/'\n",
    "    GO_data_dir = '/oak/stanford/groups/rbaltman/swang91/Sheng_repo/data/Pubmed/'\n",
    "    GO_term_file = '/oak/stanford/groups/rbaltman/swang91/Sheng_repo/data/NLP_Dictionary/go_term.txt'\n",
    "    repo_dir = '/oak/stanford/groups/rbaltman/swang91/Sheng_repo/'\n",
    "\n",
    "\n",
    "\n",
    "from pikachu.datasets.WordNet import parse_sentence\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "GO_text_dir = GO_data_dir+'GO_abstracts_test/'\n",
    "GO_pred_dir = GO_data_dir + 'GO_models_L2/'\n",
    "GO_sent_dir = GO_data_dir + 'GO_sentences_L2/'\n",
    "GO_sent_merge_dir = GO_data_dir + 'GO_sentences_L2_all/'\n",
    "\n",
    "if not os.path.exists(GO_sent_merge_dir):\n",
    "    os.makedirs(GO_sent_merge_dir)\n",
    "if not os.path.exists(GO_sent_dir):\n",
    "    os.makedirs(GO_sent_dir)\n",
    "if not os.path.exists(GO_pred_dir):\n",
    "    os.makedirs(GO_pred_dir)\n",
    "if not os.path.exists(GO_text_dir):\n",
    "    os.makedirs(GO_text_dir)\n",
    "\n",
    "\n",
    "sent_GO_term = set()\n",
    "fin = open(GO_term_file)\n",
    "ct = 0\n",
    "GO2auc = {}\n",
    "GO2key = {}\n",
    "auc_l = []\n",
    "for line in fin:\n",
    "    \n",
    "    GO = line.lower().strip()\n",
    "    #print GO\n",
    "    if GO!='dna repair':\n",
    "        continue\n",
    "    log_file = GO_pred_dir + GO.replace('/','_').replace(' ','_')+'.log'\n",
    "    if not os.path.isfile(log_file):\n",
    "        continue\n",
    "    GO2key[GO] = set()\n",
    "    flog = open(log_file)\n",
    "    for line in flog:\n",
    "        w = line.strip().split('\\t')\n",
    "        auc = float(w[0])\n",
    "        print line\n",
    "        if not w[2].isdigit():\n",
    "            continue\n",
    "        print line\n",
    "        if not np.isnan(auc) and GO not in GO2auc and w[2]>100:\n",
    "            print line\n",
    "            auc_l.append(auc)\n",
    "            GO2auc[GO] = auc\n",
    "        #break\n",
    "        if not w[1].isdigit():\n",
    "            GO2key[GO].add(w[1])\n",
    "    flog.close()\n",
    "    #break\n",
    "fin.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed finished 0 7746784 was for\n",
      "pubmed finished 3000000 52 block binding activity\n",
      "pubmed finished 6000000 28 proximal promoter box\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pubmed_word_net = 'data/Pubmed/word_network/predict_abst_180717'\n",
    "pubmed_word_net = {'data/Pubmed/word_network/all_abst_180305':'pubmed'}\n",
    "\n",
    "Net_obj_pubmed = WordNet()\n",
    "Net_obj_pubmed.ReadWordNet(pubmed_word_net,verbal=True,min_freq_cutoff=0)\n",
    "Net_obj_pubmed.ReadWordType()\n",
    "Net_obj_pubmed.ReadEdgeType(stop_word_list)\n",
    "\n",
    "pubmed_word_net =  {'data/Pubmed/word_network/predict_abst_180717':'pubmed'}\n",
    "#pubmed_word_net = 'data/Pubmed/word_network/all_abst_180305'\n",
    "Net_obj_predict = WordNet()\n",
    "Net_obj_predict.ReadWordNet(pubmed_word_net,verbal=True,min_freq_cutoff=0)\n",
    "Net_obj_predict.ReadWordType()\n",
    "Net_obj_predict.ReadEdgeType(stop_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/Pubmed/word_network/all_abst_180305'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "go2gene_set = {}\n",
    "all_genes = set()\n",
    "\n",
    "fin = open('data/NLP_Dictionary/go2gene_set_complete.txt')\n",
    "for line in fin:\n",
    "    w = line.strip().split('\\t')\n",
    "    go = w[0]\n",
    "    if go not in Net_obj_predict.edge_ct['pubmed'] or go not in Net_obj_pubmed.edge_ct['pubmed'] :\n",
    "        continue\n",
    "    go2gene_set[go] = set()\n",
    "    for i in range(1, len(w)):\n",
    "        if w[i] not in Net_obj_predict.edge_ct['pubmed']  or w[i] not in Net_obj_pubmed.edge_ct['pubmed'] :\n",
    "            continue\n",
    "        go2gene_set[go].add(w[i])\n",
    "        all_genes.add(w[i])\n",
    "fin.close()\n",
    "\n",
    "print len(go2gene_set),len(all_genes)\n",
    "\n",
    "\n",
    "cat_set = set()\n",
    "fin = open('data/NLP_Dictionary/GO_category.txt')\n",
    "go2cat = {}\n",
    "for line in fin:\n",
    "    w = line.strip().split('\\t')\n",
    "    go2cat[w[0]] = w[1]\n",
    "    cat_set.add(w[1])\n",
    "fin.close()\n",
    "\n",
    "gwet_predict = {}\n",
    "gwet_pubmed = {}\n",
    "for go in go2gene_set:\n",
    "    for g in all_genes:\n",
    "        gwet_predict[g] = gwet_predict.get(g, 0) + Net_obj_predict.edge_ct[go].get(g,0)\n",
    "        gwet_pubmed[g] = gwet_pubmed.get(g, 0) + Net_obj_pubmed.edge_ct[go].get(g,0)\n",
    "       \n",
    "    \n",
    "go2gene_sc_predict = collections.defaultdict(dict)\n",
    "go2gene_sc_pubmed = collections.defaultdict(dict)\n",
    "for go in go2gene_set:\n",
    "    for g in all_genes:\n",
    "        go2gene_sc_pubmed[go][g] = Net_obj_pubmed.edge_ct[go].get(g,0) * 1.0 / (gwet_pubmed.get(g,0) + 1)\n",
    "        go2gene_sc_predict[go][g] = Net_obj_predict.edge_ct[go].get(g,0) * 1.0 / (gwet_predict.get(g,0) + 1)\n",
    "        #if Net_obj.edge_ct[go].get(g,0)!=0:\n",
    "        #    print go,g,go2gene_sc[go][g]\n",
    "\n",
    "        \n",
    "for cat in cat_set:\n",
    "    if cat=='external':\n",
    "        continue\n",
    "    go2auc = {}\n",
    "    auc_mean_pred = []\n",
    "    auc_mean_pubmed = []\n",
    "    for go in go2gene_set:\n",
    "        if go2cat[go]!= cat:\n",
    "            continue\n",
    "        pred_predict = []\n",
    "        pred_pubmed = []\n",
    "        truth = []\n",
    "        for g in all_genes:\n",
    "            pred_predict.append(go2gene_sc_predict[go][g])\n",
    "            pred_pubmed.append(go2gene_sc_pubmed[go][g])\n",
    "            if g in go2gene_set[go]:\n",
    "                truth.append(1)\n",
    "            else:\n",
    "                truth.append(0)\n",
    "        if np.sum(truth)==0 or np.sum(pred_predict)==0 or np.sum(pred_pubmed)==0:\n",
    "            continue\n",
    "        auc_pred = evaluate_vec(pred_predict,truth)[0]\n",
    "        auc_pubmed = evaluate_vec(pred_pubmed,truth)[0]\n",
    "        #print go, auc\n",
    "        if len(go2gene_set[go])<10000:\n",
    "            #print len(go2gene_set[go]),go, auc_pred, auc_pubmed,np.mean(auc_mean_pubmed), np.mean(auc_mean_pred)\n",
    "            auc_mean_pubmed.append(auc_pubmed)\n",
    "            auc_mean_pred.append(auc_pred)\n",
    "            go2auc[go] = auc_pred\n",
    "\n",
    "    \n",
    "    fig_dir = '/srv/local/work/swang141/Sheng_repo/result/knowledge_graph/evaluate_predict_links/'\n",
    "    fig_name = 'scatter_predict_and_pubmed_'+cat+'.png'\n",
    "    scatter_plot = ScatterPlot( auc_mean_pubmed, auc_mean_pred, fig_dir = fig_dir, filename = fig_name, \n",
    "                               Ylabel = 'AUROC of Inferred edges', Xlabel = 'AUROC of Co-occured in Pubmed abstracts'\n",
    "                        ,title = cat.replace('_',' '))\n",
    "\n",
    "\n",
    "    pv = stats.wilcoxon(auc_mean_pred, auc_mean_pubmed)[1]\n",
    "    print cat, pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheng",
   "language": "python",
   "name": "sheng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
